{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6e4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876a179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pred_multi_value_feats(feats: str) -> str:\n",
    "    p = re.compile(r'([^=]+=)(.),(.)')\n",
    "    return p.sub(r'\\1\\2|\\1\\3', feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ffda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pred_toinfinitive(tag: str, feats: str) -> (str, str):\n",
    "    p = re.compile('\\|?tense=TOINFINITIVE')\n",
    "    new_feats = p.sub('', feats)\n",
    "    if feats != new_feats:\n",
    "        tag = f'{tag}_TOINFINITIVE'\n",
    "#         if not new_feats:\n",
    "#             new_feats = '_'\n",
    "        new_feats = '_'\n",
    "    return tag, new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3816966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pred_noun_suffix(tag: str, feats: str) -> (str, str):\n",
    "    if 'suf_' in feats:\n",
    "        tag = f'{tag}_S_PP'\n",
    "    return tag, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06683458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pred_row(entry: dict, cur_sent_id: int, normalize: bool) -> (list, int):\n",
    "    sent_id = int(entry['sent_id'])\n",
    "    if sent_id != cur_sent_id:\n",
    "        return [], sent_id\n",
    "    from_id, to_id, form, lemma, ctag, tag, feats, token_id = entry['from_node_id'], entry['to_node_id'], entry['form'], entry['lemma'], entry['tag'], entry['tag'], entry['feats'], entry['token_id']\n",
    "    if normalize:\n",
    "        feats = normalize_pred_multi_value_feats(feats)\n",
    "        tag, feats = normalize_pred_toinfinitive(tag, feats)\n",
    "        tag, feats = normalize_pred_noun_suffix(tag, feats)\n",
    "    return [from_id, to_id, form, lemma, ctag, tag, feats, token_id], sent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9278e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_lattice(file_path: Path, normalize: bool) -> list:\n",
    "    csv_reader = csv.DictReader(open(str(file_path)))\n",
    "    csv_rows = [row for row in csv_reader]\n",
    "    sent_id = 1\n",
    "    lattice_rows = []\n",
    "    for row in csv_rows:\n",
    "        lattice, sent_id = format_pred_row(row, sent_id, normalize)\n",
    "        lattice_rows.append(lattice)\n",
    "        if not lattice:\n",
    "            lattice, sent_id = format_pred_row(row, sent_id, normalize)\n",
    "            lattice_rows.append(lattice)\n",
    "    return lattice_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11c82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred_lattices(input_file_path: Path, output_file_path: Path, normalize: bool):\n",
    "    pred_lattice_rows = pred_to_lattice(input_file_path, normalize)\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for row in pred_lattice_rows:\n",
    "            f.write('\\t'.join(row))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbacfa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred_dir(dir_path: Path, norm_type: str):\n",
    "    normalize = norm_type == 'dep'\n",
    "    for data_type in ['test', 'dev']:\n",
    "        pred_file_path = dir_path / f'{data_type}_samples.csv'\n",
    "        pred_lattice_file_path = dir_path / f'{data_type}-hebtb-pred-{norm_type}.lattices'\n",
    "        save_pred_lattices(pred_file_path, pred_lattice_file_path, normalize=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c57fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gold_multi_value_feats(feats: str, feat_name: str) -> str:\n",
    "    p = re.compile(f'{feat_name}=.\\|{feat_name}=.')\n",
    "    m = p.search(feats)\n",
    "    if m:\n",
    "        mstr = feats[m.start(): m.end()]\n",
    "        v1 = mstr[4]\n",
    "        v2 = mstr[-1]\n",
    "        vnew = ','.join(sorted([v1, v2]))\n",
    "        feats = p.sub(f'{feat_name}={vnew}', feats)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d70d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gold_toinfinitive(tag: str, feats: str) -> (str, str):\n",
    "    if '_TOINFINITIVE' in tag:\n",
    "        tag = tag[:-len('_TOINFINITIVE')]\n",
    "        if feats == '_':\n",
    "            feats = 'tense=TOINFINITIVE'\n",
    "        else:\n",
    "            feats = f'{feats}|tense=TOINFINITIVE'\n",
    "    return tag, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1656ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_gold_noun_suffix(tag: str, feats: str) -> (str, str):\n",
    "    if '_S_PP' in tag:\n",
    "        tag = tag[:-len('_S_PP')]\n",
    "    return tag, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "810dd28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_gold_row(row: list, normalize: bool) -> list:\n",
    "    from_id, to_id, form, lemma, ctag, tag, feats, token_id = row\n",
    "    if normalize:\n",
    "        feats = normalize_gold_multi_value_feats(feats, 'gen')\n",
    "        feats = normalize_gold_multi_value_feats(feats, 'num')\n",
    "        tag, feats = normalize_gold_toinfinitive(tag, feats)\n",
    "        tag, feats = normalize_gold_noun_suffix(tag, feats)\n",
    "    return [from_id, to_id, form, lemma, ctag, tag, feats, token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a24ffbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_to_lattice(file_path: Path, normalize: bool) -> list:\n",
    "    tsv_reader = csv.reader(open(str(file_path)), delimiter='\\t', quotechar='|')\n",
    "    rows = []\n",
    "    for row in tsv_reader:\n",
    "        if row:\n",
    "            row = format_gold_row(row, normalize)\n",
    "        rows.append(row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95019df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gold_lattices(input_file_path: Path, output_file_path: Path, normalize: bool):\n",
    "    gold_lattice_rows = gold_to_lattice(input_file_path, normalize)\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for row in gold_lattice_rows:\n",
    "            f.write('\\t'.join(row))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d6a8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_norm_gold_dir(dir_path: Path):\n",
    "    gold_test_file_path = dir_path / 'test.hebtb.lgold.lattices'\n",
    "    gold_test_lattice_file_path = dir_path / 'test-hebtb-gold-morph.lattices'\n",
    "    save_gold_lattices(gold_test_file_path, gold_test_lattice_file_path, normalize=True)\n",
    "    gold_dev_file_path = dir_path / 'dev.hebtb.lgold.lattices'\n",
    "    gold_dev_lattice_file_path = dir_path / 'dev-hebtb-gold-morph.lattices'\n",
    "    save_gold_lattices(gold_dev_file_path, gold_dev_lattice_file_path, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f3caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_type = 'basic'\n",
    "bert_type = 'small'\n",
    "# bert_model = f'bert-{bert_type}-wordpiece-owt-52000-10'\n",
    "bert_model = f'bert-{bert_type}-wordpiece-oscar-52000-10'\n",
    "# bert_model = 'mbert'\n",
    "# bert_model = 'hebert'\n",
    "treebank = 'HebrewTreebank'\n",
    "tb = 'hebtb'\n",
    "root_dir = Path('experiments/morph')\n",
    "for pred_type in ['seg_only', 'seg_tag', 'seg_tag_feats']:\n",
    "    pred_dir_path = root_dir / f'morph_{pred_type}' / 'bert' / bert_type / 'wordpiece' / bert_model / treebank / tb\n",
    "    save_pred_dir(pred_dir_path, norm_type='morph')\n",
    "    if pred_type == 'seg_tag_feats':\n",
    "        save_pred_dir(pred_dir_path, norm_type='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a56b7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_dir_path = Path('/Users/Amit/dev/onlplab/yapproj/data/hebtb')\n",
    "# save_norm_gold_dir(gold_dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
